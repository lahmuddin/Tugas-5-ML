{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Principal Component Analysis (PCA).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "B83sBI5y_Gzd",
        "KtfxDyjB_KwE",
        "l-VCJT1e_OCE"
      ],
      "authorship_tag": "ABX9TyNzk90/AJjBtnPSK5C3u1z8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lahmuddin/Tugas-5-ML/blob/main/Principal_Component_Analysis_(PCA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eor1vFVKBcvl"
      },
      "source": [
        "**Lahmuddin_1103184028_TK-42-G6**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B83sBI5y_Gzd"
      },
      "source": [
        "https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_iris.html\n",
        "# PCA example with Iris Data-set\n",
        "\n",
        "Principal Component Analysis applied to the Iris dataset. The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtWXFABU78MN"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import datasets\n",
        "\n",
        "np.random.seed(5)\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "fig = plt.figure(1, figsize=(4, 3))\n",
        "plt.clf()\n",
        "ax = Axes3D(fig, rect=[0, 0, 0.95, 1], elev=48, azim=134)\n",
        "\n",
        "plt.cla()\n",
        "pca = decomposition.PCA(n_components=3)\n",
        "pca.fit(X)\n",
        "X = pca.transform(X)\n",
        "\n",
        "for name, label in [(\"Setosa\", 0), (\"Versicolour\", 1), (\"Virginica\", 2)]:\n",
        "    ax.text3D(\n",
        "        X[y == label, 0].mean(),\n",
        "        X[y == label, 1].mean() + 1.5,\n",
        "        X[y == label, 2].mean(),\n",
        "        name,\n",
        "        horizontalalignment=\"center\",\n",
        "        bbox=dict(alpha=0.5, edgecolor=\"w\", facecolor=\"w\"),\n",
        "    )\n",
        "# Reorder the labels to have colors matching the cluster results\n",
        "y = np.choose(y, [1, 2, 0]).astype(float)\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y, cmap=plt.cm.nipy_spectral, edgecolor=\"k\")\n",
        "\n",
        "ax.w_xaxis.set_ticklabels([])\n",
        "ax.w_yaxis.set_ticklabels([])\n",
        "ax.w_zaxis.set_ticklabels([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtfxDyjB_KwE"
      },
      "source": [
        "https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_lda.html?highlight=principal%20components%20analysis\n",
        "# PCA 2D projection of Iris dataset\n",
        "The Iris dataset represents 3 kind of Iris flowers (Setosa, Versicolour and Virginica) with 4 attributes: sepal length, sepal width, petal length and petal width. Principal Component Analysis (PCA) applied to this data identifies the combination of attributes (principal components, or directions in the feature space) that account for the most variance in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avb7Hvdo-vdV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "target_names = iris.target_names\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_r = pca.fit(X).transform(X)\n",
        "\n",
        "# Percentage of variance explained for each components\n",
        "print(\n",
        "    \"explained variance ratio (first two components): %s\"\n",
        "    % str(pca.explained_variance_ratio_)\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "colors = [\"navy\", \"turquoise\", \"darkorange\"]\n",
        "lw = 2\n",
        "\n",
        "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
        "    plt.scatter(\n",
        "        X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=0.8, lw=lw, label=target_name\n",
        "    )\n",
        "plt.legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
        "plt.title(\"PCA of IRIS dataset\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-VCJT1e_OCE"
      },
      "source": [
        "https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_3d.html?highlight=principal%20components%20analysis\n",
        "# Principal components analysis (PCA)\n",
        "These figures aid in illustrating how a point cloud can be very flat in one directionâ€“which is where PCA comes in to choose a direction that is not flat.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA_RQwmx9PLV"
      },
      "source": [
        "# Authors: Gael Varoquaux\n",
        "#          Jaques Grobler\n",
        "#          Kevin Hughes\n",
        "# License: BSD 3 clause\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Create the data\n",
        "\n",
        "e = np.exp(1)\n",
        "np.random.seed(4)\n",
        "\n",
        "\n",
        "def pdf(x):\n",
        "    return 0.5 * (stats.norm(scale=0.25 / e).pdf(x) + stats.norm(scale=4 / e).pdf(x))\n",
        "\n",
        "\n",
        "y = np.random.normal(scale=0.5, size=(30000))\n",
        "x = np.random.normal(scale=0.5, size=(30000))\n",
        "z = np.random.normal(scale=0.1, size=len(x))\n",
        "\n",
        "density = pdf(x) * pdf(y)\n",
        "pdf_z = pdf(5 * z)\n",
        "\n",
        "density *= pdf_z\n",
        "\n",
        "a = x + y\n",
        "b = 2 * y\n",
        "c = a - b + z\n",
        "\n",
        "norm = np.sqrt(a.var() + b.var())\n",
        "a /= norm\n",
        "b /= norm\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Plot the figures\n",
        "def plot_figs(fig_num, elev, azim):\n",
        "    fig = plt.figure(fig_num, figsize=(4, 3))\n",
        "    plt.clf()\n",
        "    ax = Axes3D(fig, rect=[0, 0, 0.95, 1], elev=elev, azim=azim)\n",
        "\n",
        "    ax.scatter(a[::10], b[::10], c[::10], c=density[::10], marker=\"+\", alpha=0.4)\n",
        "    Y = np.c_[a, b, c]\n",
        "\n",
        "    # Using SciPy's SVD, this would be:\n",
        "    # _, pca_score, Vt = scipy.linalg.svd(Y, full_matrices=False)\n",
        "\n",
        "    pca = PCA(n_components=3)\n",
        "    pca.fit(Y)\n",
        "    V = pca.components_.T\n",
        "\n",
        "    x_pca_axis, y_pca_axis, z_pca_axis = 3 * V\n",
        "    x_pca_plane = np.r_[x_pca_axis[:2], -x_pca_axis[1::-1]]\n",
        "    y_pca_plane = np.r_[y_pca_axis[:2], -y_pca_axis[1::-1]]\n",
        "    z_pca_plane = np.r_[z_pca_axis[:2], -z_pca_axis[1::-1]]\n",
        "    x_pca_plane.shape = (2, 2)\n",
        "    y_pca_plane.shape = (2, 2)\n",
        "    z_pca_plane.shape = (2, 2)\n",
        "    ax.plot_surface(x_pca_plane, y_pca_plane, z_pca_plane)\n",
        "    ax.w_xaxis.set_ticklabels([])\n",
        "    ax.w_yaxis.set_ticklabels([])\n",
        "    ax.w_zaxis.set_ticklabels([])\n",
        "\n",
        "\n",
        "elev = -40\n",
        "azim = -80\n",
        "plot_figs(1, elev, azim)\n",
        "\n",
        "elev = 30\n",
        "azim = 20\n",
        "plot_figs(2, elev, azim)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}